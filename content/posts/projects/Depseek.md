+++
title = "Kubernetes Setup: Ollama + OpenWebUI + DeepSeek-R1"
date = "2025-02-13"
description = "WdroÅ¼enie Ollamy z modelem DeepSeek-R1 na klastrze Kubernetes"
tags = ["Linux", "Kubernetes", "AI"]
categories = ["Projekty"]
draft = false
+++

# Kubernetes Setup: Ollama + OpenWebUI + DeepSeek-R1

## Opis projektu

Ten projekt przedstawia wdroÅ¼enie Ollamy, OpenWebUI i modelu DeepSeek-R1 na klastrze Kubernetes. Jest to kompletne rozwiÄ…zanie umoÅ¼liwiajÄ…ce uruchomienie wÅ‚asnego Å›rodowiska AI z interfejsem webowym.

## Wykorzystane narzÄ™dzia

- Kubernetes
- Devbox
- Taskfile
- Docker

## Architektura rozwiÄ…zania

Projekt skÅ‚ada siÄ™ z trzech gÅ‚Ã³wnych komponentÃ³w:

- **Ollama** â€“ backend AI obsÅ‚ugujÄ…cy modele jÄ™zykowe
- **OpenWebUI** â€“ przyjazny interfejs uÅ¼ytkownika do interakcji z modelami
- **DeepSeek-R1** â€“ model jÄ™zykowy zoptymalizowany pod kÄ…tem wydajnoÅ›ci

### Struktura projektu

```
.
â”œâ”€â”€ manifests/
â”‚   â”œâ”€â”€ Ingress.yaml
â”‚   â”œâ”€â”€ Namespace.yaml
â”‚   â”œâ”€â”€ Ollama.yaml
â”‚   â”œâ”€â”€ OllamaService.yaml
â”‚   â”œâ”€â”€ OpenWebUI.yaml
â”‚   â”œâ”€â”€ Service.yaml
â”‚   â””â”€â”€ Volume.yaml
â”œâ”€â”€ scripts/
â”œâ”€â”€ devbox.json
â”œâ”€â”€ devbox.lock
â”œâ”€â”€ README.md
â””â”€â”€ Taskfile.yaml
```

## Instrukcja instalacji

### Wymagania wstÄ™pne

Przed rozpoczÄ™ciem instalacji upewnij siÄ™, Å¼e masz zainstalowane:

- Klaster Kubernetes (np. Kind)
- Devbox
- Docker
- Task

### Krok po kroku

1. **Inicjalizacja i konfiguracja Devbox:**
   ```bash
   devbox init
   devbox add kubectl
   devbox add k9s
   devbox add helm
   devbox add task
   devbox add jq
   devbox add yq
   ```

2. **Uruchom Å›rodowisko Devbox:**
   ```bash
   devbox shell
   ```

2. **UtwÃ³rz dedykowanÄ… przestrzeÅ„ nazw:**
   ```bash
   task create-namespace
   ```

3. **WdrÃ³Å¼ wszystkie komponenty:**
   ```bash
   task deploy-all
   ```

4. **Poczekaj na pobranie modelu DeepSeek-R1:**
   ```bash
   task fetch-model
   ```

5. **Skonfiguruj przekierowanie portÃ³w:**
   ```bash
   task port-forward
   ```

6. **OtwÃ³rz aplikacjÄ™ w przeglÄ…darce:**
   ```
   http://localhost:3000
   ```

## PrzykÅ‚ady dziaÅ‚ania

### PrzykÅ‚ad odpowiedzi modelu na pytanie historyczne:
![DeepSeek - OdpowiedÅº na pytanie](https://azure-obliged-ox-268.mypinata.cloud/ipfs/bafkreiftk74p4yzp23vqqf7pikwr4qpofcsbrjpec2t26iwwn3offcliam)

### Generowanie kodu przez model:
![DeepSeek - Kod Pythona](https://azure-obliged-ox-268.mypinata.cloud/ipfs/bafkreiaxr3il5fkltizusxs4ukubvuhdeph5ht2l365ecbhrjrsbgjeafa)

## Konfiguracja zadaÅ„ (Taskfile)

PoniÅ¼ej znajduje siÄ™ kompletna konfiguracja zadaÅ„ w pliku `Taskfile.yaml`:

```yaml
version: "3"

tasks:
  create-namespace:
    desc: "Create namespace"
    cmds:
      - kubectl create namespace ai-stack || true

  deploy-volume:
    desc: "Deploy volume"
    cmds:
      - kubectl apply -f manifests/Volume.yaml -n ai-stack

  deploy-ollama:
    desc: "Deploy Ollama"
    cmds:
      - kubectl apply -f manifests/Ollama.yaml -n ai-stack

  deploy-openwebui:
    desc: "Deploy OpenWebUI"
    cmds:
      - kubectl apply -f manifests/OpenWebUI.yaml -n ai-stack

  deploy-service:
    desc: "Deploy Service"
    cmds:
      - kubectl apply -f manifests/Service.yaml -n ai-stack
  
  deploy-service-ollama:
    desc: "Deploy Service-ollama"
    cmds:
      - kubectl apply -f manifests/OllamaService.yaml -n ai-stack
  
  deploy-ingress:
    desc: "Deploy Ingress"
    cmds:
      - kubectl apply -f manifests/Ingress.yaml -n ai-stack

  fetch-model:
    desc: "Pobranie modelu DeepSeek dla Ollamy"
    cmds:
      - |
        echo "Czekam na start kontenera Ollama..."
        until kubectl get pod -n ai-stack -l app=ollama -o jsonpath="{.items[0].status.phase}" | grep -q "Running"; do
          sleep 5
          echo "Czekam dalej..."
        done
        echo "Kontener uruchomiony, pobieram model..."
        kubectl exec -n ai-stack $(kubectl get pod -n ai-stack -l app=ollama -o jsonpath="{.items[0].metadata.name}") -- bash -c "
          ollama run deepseek-r1:1.5b"
    silent: false

  port-forward:
    desc: "Port forwarding for OpenWebUI and Ollama"
    cmds:
      - kubectl port-forward -n ai-stack svc/openwebui 3000:80 &
      - kubectl port-forward -n ai-stack svc/ollama 11434:11434 &
    silent: false

  deploy-all:
    desc: "Deploy all components"
    cmds:
      - task: create-namespace
      - task: deploy-volume
      - task: deploy-ollama
      - task: deploy-openwebui
      - task: deploy-service
      - task: deploy-service-ollama
      - task: deploy-ingress
      - task: fetch-model

  clean:
    desc: "Clean up the environment"
    cmds:
      - kubectl delete namespace ai-stack
```

## RozwiÄ…zywanie problemÃ³w

1. **Sprawdzanie statusu wdroÅ¼enia:**
   ```bash
   kubectl get pods -n ai-stack
   ```

2. **Sprawdzanie logÃ³w:**
   ```bash
   kubectl logs -n ai-stack -l app=openwebui
   kubectl logs -n ai-stack -l app=ollama
   ```

3. **Wymagania sprzÄ™towe:**
   - Minimum 8GB RAM
   - 4 rdzenie CPU
   - 20GB przestrzeni dyskowej

## Uwagi koÅ„cowe

- Model DeepSeek-R1 jest zoptymalizowany pod kÄ…tem wydajnoÅ›ci, ale moÅ¼e dziaÅ‚aÄ‡ wolniej na sÅ‚abszych maszynach
- Model jak widac dziala , troche zajmuje mu odpowiadanie na pytania 
- W przypadku problemÃ³w z dostÄ™pem do interfejsu, sprawdÅº status przekierowania portÃ³w
- Regularnie monitoruj zuÅ¼ycie zasobÃ³w klastra

---

 
ðŸš€ **Powodzenia w implementacji!**
